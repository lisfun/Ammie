Ammie 白皮书  v0.1

f(symbols, scene) → Action + Explain

AMI：Auditable Machine Intelligence
一种符号优先、场景感知、LLM 辅助的个人 AI Agent 架构

---
导语：

“智能是约束的结果，而非规模。”

我们发布了 Ammie (AMI) 技术白皮书 v0.1。这是一次让 LLM 回归工具本位、让符号系统重新主导决策的尝试。我们不追求全知全能，我们追求的是每一个动作都可被审计，每一个错误都可被回溯。

0. 引言：为什么符号化智能在LLM时代可以成功？

在人工智能的发展史上，符号主义（Symbolic AI） 曾是最早的主流范式。它试图用逻辑规则、语义网络和知识库来模拟人类智能，其核心信念是：智能可以归结为对符号的操作。然而，到了20世纪80年代末，符号主义遭遇了难以逾越的瓶颈：

· 知识获取瓶颈：所有规则和事实都需要人工编写，不仅耗时费力，而且难以覆盖现实世界的无穷变化。
· 规则刚性：符号系统缺乏处理模糊性、歧义和常识的能力，一旦遇到规则未覆盖的情况，就会“脆断”。
· 上下文缺失：无法有效利用语境信息，导致对自然语言的理解停留在字面层面。
· 维护成本高：随着知识库增长，规则冲突和一致性问题变得难以管理。

这些缺陷使得符号系统在现实应用中举步维艰，最终被连接主义（神经网络） 的浪潮所取代。大规模语言模型（LLM）通过海量数据训练，展现出惊人的语言生成和理解能力，似乎宣告了符号主义的终结。

但LLM并非万能。它们本质上是概率模型，缺乏稳定的知识表征、可解释的推理链路和可控的行为边界。在实际应用中，我们不得不通过提示工程、函数调用、输出约束等手段层层限制LLM，才能使其在特定任务中可靠工作——这恰恰暴露了LLM作为“智能体”的根本缺陷：它们可以被咨询，但难以被信任。

LLM的出现，并没有否定符号主义，反而为符号系统提供了缺失的那块拼图。

· 自动知识获取：LLM可以从自然语言中提取结构化信息，填补符号系统的知识库。过去需要人工编写的词典、规则、本体，现在可以通过与LLM的交互自动生成。
· 处理模糊性：LLM擅长理解歧义、省略和口语表达，能够为符号解析提供候选解释，再由符号系统根据场景和规则做最终决策。
· 提供常识背景：LLM蕴含的广泛世界知识，可以辅助符号系统处理未见过的概念，避免“脆断”。

更重要的是，符号系统依然保留着不可替代的优势：

· 可审计：每一个决策都可以追溯到明确的符号和规则，而非神经网络的黑箱权重。
· 可演化：知识以结构化形式存储，用户可以随时查看、修正、扩展，实现真正的个性化成长。
· 可控：行为边界由显式规则定义，永远不会产生意料之外的输出。
· 本地优先：符号系统轻量高效，可以完全运行在本地，保护用户隐私。

因此，Ammie的核心理念应运而生：

让LLM回归工具本位，成为符号系统的“外挂知识源”；让符号系统主导决策，成为可审计、可演化的智能核心。

这不是对连接主义的否定，而是对两种范式的扬长避短。在LLM的赋能下，符号化智能终于可以跨越历史瓶颈，走向真正实用、可靠、属于个人的智能体。

---

1. 核心文件总览

Ammie Core v0.1 由以下 6 个核心文件 构成，任何实现必须包含等价模块。

文件名 职责
symbols.json 符号 ↔ 原意的桥梁，将自然语言词汇映射为稳定语义符号。
scenes.json 场景的“物理法则”，定义 4W（WHO/WHAT/WHEN/WHERE）的元模型与动态规则。
ontology.json 本体论标签系统，定义实体存在性与可执行性，作为语义合法性守门人。
capabilities.json 语义 → 行为的映射，声明可执行的最小动作单元及其接口。
llm_bridge.py 极简 LLM 翻译官，封装对语言模型的调用，严格限制输出格式与权限。
dialogue.py 对话核心引擎，负责输入解析、场景维护、能力调度与响应生成。

---

2. symbols.json —— 符号与原意的桥梁

2.1 职责

将自然语言词汇（包括同义词、口语变体）映射为稳定的语义符号（canonical symbol），供后续意图识别使用。

2.2 基本结构

```json
{
  "version": "1.0.0",
  "symbols": {
    "open": {
      "canonical": "START",
      "pos": ["verb"],
      "aliases": ["begin", "launch", "turn_on"],
      "confidence": 0.92
    },
    "我": {
      "canonical": "SELF",
      "pos": ["pronoun"],
      "resolves_to": "user"
    },
    "音乐": {
      "canonical": "MUSIC",
      "pos": ["noun"],
      "intent": "PLAY_MUSIC"   // 可选，直接关联意图
    }
  }
}
```

2.3 设计原则

· ❌ 不存储完整句子或 LLM 原始输出。

· ✅ 只存储稳定意义。

· ✅ 允许多个词汇映射到同一个 canonical。

· ✅ 支持相似性猜测（如拼写错误、方言、口语）通过 aliases 或置信度调整。


---

3. scenes.json —— 场景的物理法则（4W）

3.1 Scene 的定义

Scene 是语言发生的物理上下文，而非语义本身。在 Ammie 中，Scene 必须且只能由 4W 构成：

维度 含义 示例值
WHO 参与者 "self", "user", "third"
WHAT 事件/意图 "WORK", "ENTERTAINMENT"
WHEN 时间 "morning", "2025-03-21"
WHERE 空间 "home", "office", "outdoor"

3.2 Scene Grammar（元模型）

```json
{
  "version": "1.0.0",
  "scene_model": {
    "WHO": {
      "types": ["self", "user", "third_party"],
      "default": "user"
    },
    "WHAT": {
      "types": ["intent", "object"],
      "required": true
    },
    "WHEN": {
      "types": ["now", "relative", "absolute"],
      "default": "now",
      "expiry": "30s"
    },
    "WHERE": {
      "types": ["local", "remote", "virtual"],
      "default": "virtual"
    }
  }
}
```

3.3 Scene 动态机制（Scene+）

Scene+ 不是增加维度，而是以下三种隐式机制：

1. 继承（Inheritance）
   当前 Scene 未声明的字段，自动继承上一个 Scene 的对应值（除非显式覆盖）。
2. 过期（Decay）
   每个 Scene 字段可带有效期（如 expiry），超过后自动失效，回退为默认值或空。
3. 冲突解决（Resolution）
   当用户输入与当前 Scene 冲突时，以新输入为准，并记录冲突用于后续学习。

3.4 场景规则（可选扩展）

scenes.json 也可包含具体的场景规则，用于在特定 4W 组合下直接触发意图或能力。例如：

```json
{
  "rules": [
    {
      "id": "rule_001",
      "conditions": {
        "WHERE": "home",
        "WHEN": "evening",
        "WHAT": "entertainment"
      },
      "action": {
        "intent": "PLAY_MUSIC",
        "params": { "playlist": "default" }
      },
      "priority": 10
    }
  ]
}
```

---

4. ontology.json —— 本体论标签系统

4.1 职责

Ontology 用于判断：“这件事在 Ammie 的世界里是否存在、是否可执行”。它是语义合法性的守门人，但不做推理，不调用 LLM。

4.2 基本结构

```json
{
  "version": "1.0.0",
  "entities": {
    "time": {
      "type": "abstract",
      "actions": ["get", "compare"]
    },
    "news": {
      "type": "information",
      "actions": ["fetch", "notify"]
    },
    "音乐": {
      "type": "media",
      "actions": ["play", "stop", "search"]
    }
  },
  "intent_to_capability": {
    "PLAY_MUSIC": "play_music",
    "QUERY_TIME": "get_time"
  }
}
```

4.3 设计原则

· ❌ 不做推理（如不自动推导子类关系）。（允许一级父类关联，禁止多级递归，确保审计链路清晰。）


· ❌ 不存储实例数据（如“贝多芬的第五交响曲”）。（本体论仅存储 Schema，实例数据由独立的 Memory 模块或 RAG 维护，由用户定义存储边界。）


· ✅ 只回答：给定实体和动作，是否合法。


· ✅ 意图到能力的映射可放在此处，也可放在 capabilities.json，根据项目规模选择。



---

5. capabilities.json —— 能力映射

5.1 定义

Capability = 可执行的最小动作单元，包含输入输出接口，可能对应一段脚本或函数。

```json
{
  "version": "1.0.0",
  "capabilities": [
    {
      "name": "play_music",
      "intent": "PLAY_MUSIC",
      "description": "播放音乐",
      "input_schema": {
        "song": { "type": "string", "optional": true },
        "playlist": { "type": "string", "optional": true }
      },
      "output_schema": {
        "status": { "type": "string", "enum": ["playing", "error"] }
      },
      "tags": ["娱乐", "媒体"],
      "executor": "music_player"   // 指向具体实现模块
    },
    {
      "name": "get_time",
      "intent": "QUERY_TIME",
      "description": "获取当前时间",
      "input_schema": {},
      "output_schema": {
        "time": { "type": "string" }
      },
      "tags": ["工具"],
      "executor": "system_time"
    }
  ]
}
```

5.2 能力发现机制（高级特性）

当用户请求无法匹配现有能力时，系统可：

1. 将用户输入与当前场景提交给 LLM。
2. LLM 返回候选能力的 JSON 描述（必须符合 capabilities.json 的 schema）。
3. 将候选存入“待审核区”，经用户确认或多次成功使用后自动加入正式能力库。

---

6. llm_bridge.py —— 极简翻译官

6.1 定位

LLM 不是智能体，只是一个不可靠但强大的外部解释器。所有调用必须遵循严格约束。

6.2 接口设计

```python
class LLMBridge:
    def __init__(self, config):
        self.backend = config.get("backend", "openai")  # 或 "ollama"
        self.model = config.get("model", "gpt-3.5-turbo")
        self.cache = {}

    def ask(self, prompt: str, expected_schema: dict = None) -> dict:
        """发送请求，返回 JSON，若不符合 schema 则重试或返回 None"""
        # 实现包括缓存、重试、超时、格式校验
```

6.3 严格限制

· ✅ 只允许：
  · 词义归纳（解释未知词）
  · 相似性建议（给出候选意图或能力）
  · 输出 JSON 格式
· ❌ 禁止：
  · 直接写入核心文件（基础符号及本体论构建阶段，我们默认新人LLM，允许直接写入，人类只做时候纠错员，不做事前审查员。）
  · 执行决策
  · 控制流程
  · 生成自由文本响应（除非用于用户可读的解释）

---

7. dialogue.py —— 对话核心引擎

7.1 输入处理流程

```
用户输入
    ↓
分词与符号匹配（symbols.json）
    ↓
解析出基础框架（动词、宾语、修饰语）
    ↓
场景补全（利用当前 Scene 填充缺失槽位、消歧）
    ↓
本体合法性检查（ontology.json）
    ↓
能力匹配（capabilities.json）
    ↓
执行（或触发分歧询问/学习）
    ↓
输出响应
```

7.2 核心数据结构

· Scene 类：维护当前会话的 4W 信息，包含客观层（如系统时间）和提及层（如用户提到的地点）。
· DialogState 类：记录待处理的询问、重试次数等。

7.3 关键方法

```python
def process_input(user_input: str) -> str:
    # 完整处理逻辑
    pass

def _parse(text: str) -> ParsedFrame:
    # 基于 symbols 的简单解析
    pass

def _resolve_capabilities(parsed: ParsedFrame, scene: Scene) -> List[Capability]:
    # 根据意图和场景，返回候选能力列表
    pass

def _execute_capability(cap: Capability, params: dict) -> str:
    # 模拟或实际执行，返回用户可读的结果
    pass

def _ask_clarification(candidates: List[Capability]) -> str:
    # 生成询问语句，并记录状态
    pass
```

7.4 反向句子构建（自主解释机制）

Ammie 必须仅使用其已学习的词汇来解释其行为。

如果系统拒绝某个动作，解释必须根据符号的 S-V-O（主-谓-宾）结构自主构建，禁止由 LLM 直接生成。

工作流示例：

1.Input / 输入: "你会打篮球吗？"

2.Recognition / 识别: 系统发现“篮球”为未知词汇。

3.LLM Inquiry / LLM 咨询: 向 LLM 获取“篮球”的 canonical 符号及 ontology 属性。

4.Update / 更新: 自动补充 symbols.json 和 ontology.json。

5.Autonomous Construction / 自主构建:

6.Logic / 逻辑: ammie (S) + NEG_POTENTIAL (V_mod) + ACTION_PLAY (V) + OBJ_BASKETBALL (O)。

7.Output / 输出: "我（S）+ 不会（V_mod）+ 打（V）+ 篮球（O）。"

---

8. 核心抽象

行为函数：

```
f(symbols, scene) → Action + Explain
```

其中：

· words：用户输入的自然语言。
· scene：当前会话的 4W 上下文。
· action：系统执行的动作（可以是能力调用、询问、学习请求等）。

该函数不是端到端模型，而是可拆解的因果链，每一步都可审计。

---

9. 关键机制扩展（可选，但推荐）

9.1 分歧询问系统

当多个候选能力置信度均低于阈值时，系统主动提问以澄清意图。

· 触发条件：候选列表长度 > 1，且最高置信度 < 阈值（如 0.7）。
· 问题生成：基于候选能力名称或参数，生成自然语言问题（如“你想播放音乐还是视频？”）。
· 回答解析：通过关键词匹配或简单语义理解，确定用户选择。
· 状态管理：询问上下文保存在 DialogState 中，处理用户回答后清除。

9.2 用户规则库

允许用户显式教导系统在特定场景下执行特定动作。

· 规则格式：与场景规则类似，但优先级高于通用规则。
· 存储位置：可独立为 user_rules.json，或合并入 scenes.json 并标记来源。
· 管理接口：提供命令或 UI 查看、添加、删除规则。

9.3 行为模式检测与主动建议

系统可记录用户在不同场景下的历史选择，当检测到重复模式时，主动询问是否要创建规则。

· 记录内容：(scene_fingerprint, input_pattern, selected_action, timestamp)
· 检测算法：统计相同模式下用户的选择分布，超过阈值（如 3 次一致）则触发建议。
· 交互：“我注意到你经常在晚上在家时播放音乐，需要我以后自动这么做吗？”用户可选择“是”创建规则，“否”忽略，“不再询问”关闭此功能。

9.4 记忆模块

长期存储用户偏好、常用实体、交互历史摘要等，用于初始化场景和优化规则。

· 存储：本地 JSON 文件或轻量数据库（如 SQLite）。
· 内容：不存储原始对话，只存储统计信息和用户显式教导。
· 隐私：所有数据本地存储，用户可随时查看和清除。

---

10. 非目标（Non-Goals）

· ❌ 情绪模拟
· ❌ 人格扮演
· ❌ 端到端大模型
· ❌ 不可解释推理
· ❌ 云端依赖
· ❌ 多模态感知（初期）

---

11. 结语

Ammie 不是 LLM 的替代品，而是让 LLM 回归工具本位的一次尝试。如果没有 LLM，这套系统难以扩展；如果让 LLM 主导，这套系统必然失控。

通过符号优先、场景感知、本地运行的设计，Ammie 旨在成为真正可审计、可演化、忠于用户的个人智能体。

欢迎社区参与讨论与贡献。

---

版本历史

· v0.1 (2026-02-17)：初始核心规范发布。
